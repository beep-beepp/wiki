### 지원

# Parallel GC

## 1. 목적

Parallel GC는 STW 시간을 줄이면서도 Throughput을 극대화하기 위해 만들어졌다.
즉, 여러 GC 스레드가 병렬로 Young/Old 영역을 처리함으로써 STW 시간을 줄이고, CPU를 최대로 활용하는 전략이다.
latency보다 throughput을 우선시하는 GC이다.

## 2. 왜 나왔는가?

초기 JVM은 Serial GC만 존재했다.
Serial GC는 단일 스레드로 동작하기 때문에 CPU가 많아도 활용을 못했다.
멀티코어 프로세서가 등장하면서, GC도 병렬 처리가 필요해졌고, 그 결과로 나온게 Parallel GC이다.

## 3. 작동 방식

### Minor GC 
발생 조건 : Eden이 가득찼을때 발생

**총 과정 : STW -> Parallel Mark -> Copy(Survivor/Old로 Promotion 포함) -> Free -> STW 해제**

| **단계**               | **병렬 여부** | **설명**                                                                                                                                                                                                                        |
|----------------------|-----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1) STW 발생            | X         | 모든 애플리케이션 스레드 정지하고 GC 스레드만 실행                                                                                                                                                                                                 |
| 2) Parallel Mark     | O         | GC Root set(스택변수, 레지스터, static 필드 등)에서 Young 영역 내 직접 참조 중인 객체만 찾음. <br/>이 객체들이 살아 있으면 mark 함.<br/>(살아있는 객체를 빠르게 판별하기 위한 얕은 참조 스캔.)                                                                                            |
| 3) Parallel Copy     | O         | 살아남은 객체를 남은 Survivor 영역이나 Old 영역으로 Copy함. <br/>(Survivor 영역이 가득 찼거나, 객체가 여러번 Young GC를 살아남았으면 Old 영역으로 promotion됨.)<br/><br/> 죽은 객체가 있던 버려진 공간은 다시 쓸 수 있도록 표시하는데, 그 빈 공간 목록이 free list임 <br/>(즉, 다음에 객체를 새로 만들 때 사용할 빈 주소 목록) |
| 4) Free (Eden/S0 정리) | O         | Eden/S0 영역을 비워서 재사용 가능 상태로 만듦. Free list 업데이트함.                                                                                                                                                                               |
| 5) STW 해제            | X         | GC 스레드 종료 후 애플리케이션 스레드 재개                                                                                                                                                                                                     |

### Major GC
발생 조건 : Old가 가득찼을 때 발생

**총 과정 : STW -> Parallel Mark -> Summary -> Parallel Compact -> Free -> STW 해제**

| **단계**              | **병렬 여부** | **설명**                                                                                                                                                   |
|---------------------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1) STW 발생           | X         | 모든 애플리케이션 스레드 정지하고 GC 스레드만 실행                                                                                                                            |
| 2) Parallel Mark    | O         | GC Root set(스택변수, 레지스터, static 필드 등)를 스캔해 참조 시작점을 수집함.<br/>이 루트에서 연결된 객체 그래프를 따라가며 살아있는 객체를 Mark Bitmap에 표시함.<br/>(Root에서 시작해서 Old영역 전체 객체 그래프를 깊게 탐색함.) |
| 3) Summary (준비 단계)  | O         | Compact 단계 전, Old 영역 전체를 Region/Chunk/Card 단위로 나눠, <br/>각 영역에서 살아남은 객체들의 크기를 요약해 Compact 단계에서 객체를 이동시킬 위치를 계산하는 과정.                                      |
| 4) Parallel Compact | O         | 살아있는 객체를 앞으로 몰아서 연속된 공간으로 압축함. 죽은 객체 영역은 제거함.                                                                                                            |
| 5) Free             | O         | 남은 빈 영역을 free list로 등록함.                                                                                                                                 |
| 6) STW 해제           | X         | GC 스레드 종료 후 애플리케이션 스레드 재개                                                                                                                                |

## 4. 장단점

| **구분** | **장점**             | **단점**                        |
|--------|--------------------|-------------------------------|
| 성능     | 멀티코어 활용으로 GC 속도 빠름 | GC 스레드가 많을수록 CPU 부하 증가        |
| 처리량    | throughput 극대화     | STW는 여전히 존재                   |
| 튜닝 난이도 | 파라미터 적고 단순         | 세밀한 지연 제어 불가능                 |
| 힙 크기   | 중간 크기(4~16GB)에 최적  | 대형 힙(>32GB)에서는 Full GC 시간 길어짐 |
| 예측성    | 동작 일관적, 안정적        | 지연 폭이 큼 (Full GC 시 수초 단위)     |

### ❓ "동작 일관적, 안정적" 무슨 뜻?

"안정적"이란 말은 "버그 없이 잘 처리한다"는 뜻이 아니고 "예측 가능한 성능 패턴"을 뜻한다.
즉, "특정 워크로드에서 매번 유사한 GC 패턴과 지연시간을 보인다" 라는 의미로 이해하자.

| **구분**          | **Serial GC** | **Parallel GC** | **CMS GC**                                 | **G1 GC**                    | **ZGC**                   |
|-----------------|---------------|-----------------|--------------------------------------------|------------------------------|---------------------------|
| 스레드 수           | 1개            | 여러 개            | 여러 개 (병렬 + 동시)                             | 여러 개 (병렬 + 동시)               | 여러 개 (병렬 + 동시)            |
| 알고리즘 복잡도        | 매우 단순         | 단순              | 중간                                         | 복잡                           | 매우 복잡                     |
| 결과의 일관성(예측 가능성) | 매우 일정         | 매우 일정           | 다소 불안정<br/>(Concurrent 단계 실패 시 Full GC 가능) | 일정 (Pause 기반 목표 제어)          | 매우 일정                     |
| 성능 변동성          | 낮음            | 낮음              | 중간~높음<br/>(Concurrent Mode Failure시 지연 급등) | 낮음                           | 매우 낮음                     |
| 튜닝 난이도          | 매우 쉬움         | 쉬움              | 중간(파라미터 많음)                                | 쉬움~중간(대부분 자동 조정)             | 매우 어려움(고급 영역)             |
| Fragmentation   | X(압축)         | X(압축)           | O(압축 안함)                                   | X(Copy - Compact)            | X                         |
| 대형 힙 대응력        | 낮음            | 보통              | 낮음(Concurrent 부하 높아짐)                      | 높음                           | 매우 높음                     |
| 대표 목표           | 단순함           | Throughput 극대화  | Low pause                                  | Balanced(throughput + pause) | Ultra low pause(realtime) |

### ❓ "지연 폭이 큼" 무슨 뜻?

"지연 폭이 크다"는 건 GC가 일어날 때 멈추는 시간이 들쭉날쭉하고, 최악의 경우 몇 초 동안 멈출 수도 있다는 뜻이다.
즉, 대부분의 경우는 빠르지만, 가끔 Old 영역이 가득 찼을 때 아주 긴 STW가 발생할 수 있다는 위험이 있다는 뜻이다.

## 5. 언제 쓰면 좋을 까?

- Latency보단 Throughput이 중요한 서비스 -> 배치 처리, 백엔드 API 서버, 로그 수집 등
- 코어가 많고, 힙 크기가 중간(4~16GB 수준) -> CPU 병렬화 효과가 극대화됨.
- 응답 시간보다 Throughput이 KPI인 시스템 -> 데이터 ETL, 집계, 통계 계산, 추천 엔진 전처리 등

### ❓ 왜 중간 힙에 최적일까?

| **힙 크기**          | **영향**                      | **이유**                                                                         |
|-------------------|-----------------------------|--------------------------------------------------------------------------------|
| 작은 힙(1~2GB 이하)    | GC 빈도 많아짐 -> Minor GC 자주 발생 | 할당 속도가 수거 속도보다 빠름. 병렬 이점이 크지 않음. <br/>Serial이 오히려 효율적일 수 있음.                   |
| 중간 힙(4~16GB)      | 병렬 수거 효과 극대화                | 스레드 간 분할 효율이 좋고, Full GC도 수 초내 끝남. Throughput이 가장 높음.                          |
| 대형 힙(32GB 이상)     | Full GC 한번에 수 초 ~ 수십 초 가능   | Mark-Compact 범위가 너무 넓음. STW 시간이 길어지고, 캐시/로컬 히트를 저하.                            |
| 초대형 힙(100GB 이상)   | 사실상 운영 불가 수준                | Parallel GC는 힙을 전부 스캔/압축하므로 지연 폭이 너무 큼. G1, ZGC 같은 region 기반 concurrent GC 필요. |
| 대형 힙 (100GB 이상)** | 사실상 운영 불가 수준                | Parallel GC는 힙을 전부 스캔·압축하므로 지연 폭이 너무 큼. G1, ZGC 같은 region 기반 concurrent GC 필요. |

## 6. 결론

Parallel GC는 STW 동안 GC 작업을 멀티스레드로 병렬 수행하여 전체 Throughput을 높이는 GC로, Throughput이 중요한 서버 환경에는 적합하지만,
지연시간이 중요한 시스템에는 부적합하다.
