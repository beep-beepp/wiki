# Replica

Created: October 23, 2025 7:44 AM
Status: Not started
발표일자: October 29, 2025

1. Load Balancing
2. High Availability
3. Backup / Data protection

### Streaming Replic (물리적 복제)

장점

1. 성능이 매우 빠르다. 
2. 설정이 간단하다.
3. 전체가 완벽하게 동기화 된다.
4. 복제 지연이 거의 없다.

단점

1. 읽기 전용이다.
2. 특정 테이블만 복제는 불가능
3. 복제본에서 추가 인덱스등 쓰기 불가.

### Logical Replication (논리적 복제)

장점

1. 특정 테이블만 복제가능
2. 쓰기 가능
3. 복제본에서 추가 인덱스나 테이블 생성가능

단점

1. 느림 (SQL 레벨 처리요청이여서)
2. 설정 복잡
3. 충돌 처리시 직접 관리 필요.

# Oracle Write Replica

### Data Guard - Logical Standby

**개요**

- 논리적 복제 방식의 Data Guard
- SQL Apply를 사용한 복제

**작동 방식**

`Primary DB → Redo Log 전송 → SQL 변환 → Logical Standby DB
(LogMiner를 통한 SQL 재생)`

**특징**

- Redo Log를 SQL 문으로 변환하여 적용
- Standby가 읽기/쓰기 가능 (추가 테이블 생성 가능)
- 선택적 테이블 복제 가능

**장점**

- Standby에서 읽기/쓰기 모두 가능
- 보고서 생성, 추가 인덱스 생성 가능
- 데이터 변환 가능

**단점**

- Physical Standby보다 느림
- 일부 데이터 타입 미지원 (LOB, Collection 등)
- 복잡한 관리
- 최근에는 거의 사용 안함 (GoldenGate 선호)

---

### Oracle GoldenGate

**개요**

- 실시간 데이터 복제 및 통합 플랫폼
- 가장 유연하고 강력한 논리적 복제 솔루션

**작동 방식**

`Source DB → Extract → Trail Files → Replicat → Target DB
(Transaction 로그 기반 CDC)`

**특징**

- 이기종 데이터베이스 간 복제 가능
- 실시간 Change Data Capture (CDC)
- 양방향 복제 지원
- 데이터 변환 및 필터링 강력

**장점**

- 최고의 유연성 (Oracle ↔ MySQL, PostgreSQL 등)
- 선택적 테이블 복제
- 실시간 데이터 통합
- 양방향 Active-Active 구성 가능
- Zero Downtime Migration 지원
- 데이터 변환 및 매핑 가능

**단점**

- 별도 라이선스 필요 (고가)
- 복잡한 설정 및 관리
- 높은 학습 곡선
- 추가 리소스 필요 (Extract/Replicat 프로세스)

**사용 사례**

- 이기종 DB 간 데이터 동기화
- 실시간 데이터 웨어하우스
- 클라우드 마이그레이션
- Active-Active 구성

---

### Write replica가 필요한 경우 - 지원님 질문

## 📊 아키텍처 비교 개요

### 1️⃣ 전통적 방식 (Write Replica 없음)

```
                    Primary DB
                    (Read/Write)
                         |
        +----------------+----------------+
        |                |                |
   Read Replica    Read Replica    Read Replica
   (Read Only)     (Read Only)     (Read Only)

```

### 2️⃣ Multi-Write 방식 (Write Replica 있음)

```
    Write Node 1        Write Node 2        Write Node 3
    (Read/Write)        (Read/Write)        (Read/Write)
         |                    |                    |
         +--------------------+--------------------+
                    양방향 복제

```

---

## 🌍 시나리오 1: 글로벌 전자상거래 서비스

### 배경

- 한국, 일본, 미국에 사용자 분산
- 주문 처리, 재고 관리, 상품 리뷰 등

---

### ❌ Write Replica 없을 때

**아키텍처:**

```
서울에 Primary DB 위치

한국 사용자 → 서울 Primary (10ms)
일본 사용자 → 서울 Primary (50ms)
미국 사용자 → 서울 Primary (150ms)

```

**실제 시나리오:**

### 상황 1: 미국 사용자가 주문

```
시간 경과:
0ms   : 미국 사용자 "구매" 버튼 클릭
150ms : 서울 Primary에 INSERT 요청 도착
160ms : DB 쓰기 완료
310ms : 미국 사용자에게 응답 도착

```

→ **총 310ms 소요** (사용자 체감 느림)

### 상황 2: Primary DB 서버 장애

```
09:00 - 서울 Primary 장애 발생
09:00 - 모든 지역 쓰기 불가능 ❌
09:05 - Read Replica를 Primary로 승격 시작
09:10 - 승격 완료, 쓰기 재개

```

→ **10분간 전체 서비스 쓰기 중단**

### 상황 3: 네트워크 문제

```
한국-미국 해저케이블 장애
→ 미국 사용자 주문 불가 ❌
→ 네트워크 복구까지 서비스 중단

```

**주요 문제점:**

- 😢 지리적으로 먼 사용자는 느린 쓰기 응답
- 😢 단일 장애점 (Single Point of Failure)
- 😢 네트워크 문제에 취약
- 😢 Primary 부하 집중 (모든 쓰기)

---

### ✅ Write Replica 있을 때

**아키텍처:**

```
한국 Write Node ← 한국 사용자 (10ms)
일본 Write Node ← 일본 사용자 (10ms)
미국 Write Node ← 미국 사용자 (10ms)
     ↓↓↓ 양방향 복제 ↓↓↓

```

**실제 시나리오:**

### 상황 1: 미국 사용자가 주문

```
시간 경과:
0ms   : 미국 사용자 "구매" 버튼 클릭
10ms  : 미국 로컬 DB에 INSERT
15ms  : 미국 사용자에게 응답 도착
백그라운드: 한국, 일본 노드로 복제 (비동기)

```

→ **총 15ms 소요** (20배 빠름! 🚀)

### 상황 2: Primary DB 서버 장애

```
09:00 - 서울 Write Node 장애 발생
09:00 - 일본/미국 노드는 정상 작동 ✅
09:00 - 한국 사용자 → 일본 노드로 자동 라우팅

```

→ **0초 다운타임** (무중단!)

### 상황 3: 네트워크 문제

```
한국-미국 해저케이블 장애
→ 각 지역은 로컬 노드에서 계속 쓰기 ✅
→ 네트워크 복구 시 자동 동기화

```

**주요 장점:**

- 😊 모든 사용자가 빠른 쓰기 응답 (로컬)
- 😊 고가용성 (한 노드 장애해도 서비스 정상)
- 😊 네트워크 문제에 강함
- 😊 쓰기 부하 분산

**주의사항:**

```
⚠️ 충돌 가능성:
한국: 상품 A 재고 10 → 5로 변경
미국: 상품 A 재고 10 → 3으로 변경
→ 충돌 해결 필요 (Last Write Wins 등)

```

---

## 🎮 시나리오 2: 실시간 게임 서비스

### 배경

- MMORPG 게임
- 플레이어 위치, 아이템 획득, 전투 기록

---

### ❌ Write Replica 없을 때

**구조:**

```
중앙 Primary DB (서울)

```

**게임 플레이 시나리오:**

```
미국 플레이어가 아이템 습득:

0ms   : 플레이어가 아이템 클릭
150ms : 서울 서버에 UPDATE 요청
160ms : DB 쓰기 완료
310ms : 플레이어에게 "아이템 획득" 표시

```

**플레이어 경험:**

- 아이템 클릭 → 0.3초 후 인벤토리 업데이트
- 버벅거리는 느낌
- "렉 걸린다" 불만

**동접자 증가 시:**

```
Primary DB 부하:
- 평상시: CPU 40%
- 이벤트 시: CPU 95% → 응답 지연 발생
- 모든 지역 플레이어 영향 받음

```

---

### ✅ Write Replica 있을 때

**구조:**

```
한국 서버 + DB ← 한국 플레이어
일본 서버 + DB ← 일본 플레이어
미국 서버 + DB ← 미국 플레이어

```

**게임 플레이 시나리오:**

```
미국 플레이어가 아이템 습득:

0ms  : 플레이어가 아이템 클릭
5ms  : 미국 로컬 DB에 UPDATE
10ms : 플레이어에게 "아이템 획득" 즉시 표시
백그라운드: 다른 지역 복제

```

**플레이어 경험:**

- 아이템 클릭 → 즉시 인벤토리 업데이트
- 부드러운 게임 플레이
- "렉 없음" 만족

**동접자 증가 시:**

```
각 지역 DB 독립 운영:
- 한국 이벤트 → 한국 DB만 부하 증가
- 일본/미국 플레이어는 영향 없음
- 부하 분산 효과

```

---

## 🏦 시나리오 3: 은행 멀티 지점 시스템

### 배경

- 전국 100개 지점
- 계좌 조회, 입출금, 송금

---

### ❌ Write Replica 없을 때

**구조:**

```
본사 중앙 DB
    ↓
모든 지점이 VPN으로 중앙 DB 접속

```

**실제 업무 시나리오:**

### 고객이 제주 지점에서 출금

```
제주 지점 → 서울 본사 DB (50ms)

```

**정상 상황:**

- 출금 처리 시간: 약 100ms
- 큰 문제 없음

**문제 상황 1: 본사 DB 장애**

```
10:00 - 본사 DB 서버 장애
10:00 - 전국 100개 지점 모두 업무 중단 ❌
10:30 - DB 복구 완료

```

→ **30분간 전국 은행 업무 마비**

**문제 상황 2: 네트워크 장애**

```
제주-서울 네트워크 단절
→ 제주 지점 업무 완전 중단 ❌
→ 고객 불만 폭발

```

---

### ✅ Write Replica 있을 때

**구조:**

```
각 지역별 Write Node:
- 서울 권역 DB
- 부산 권역 DB
- 제주 권역 DB
    ↓↓↓
  실시간 동기화

```

**실제 업무 시나리오:**

### 고객이 제주 지점에서 출금

```
제주 지점 → 제주 로컬 DB (5ms)
백그라운드: 서울/부산 DB로 복제

```

**정상 상황:**

- 출금 처리 시간: 약 10ms (10배 빠름)

**문제 상황 1: 서울 DB 장애**

```
10:00 - 서울 DB 서버 장애
10:00 - 서울 지점만 부산/제주 DB로 전환
10:00 - 부산/제주 지점은 정상 업무 ✅

```

→ **다른 지역 영향 없음, 서울도 즉시 전환**

**문제 상황 2: 네트워크 장애**

```
제주-본토 네트워크 단절
→ 제주는 로컬 DB로 계속 업무 ✅
→ 네트워크 복구 후 자동 동기화

```

**추가 장점:**

```
규정 준수:
- 제주 고객 데이터는 제주에 저장
- 지역별 데이터 주권 만족
- 백업도 지역별로 가능

```

---

## 📈 성능 지표 비교

### 쓰기 레이턴시 (지리적 거리별)

| 사용자 위치 | Write Replica 없음 | Write Replica 있음 | 개선율 |
| --- | --- | --- | --- |
| **로컬 (서울-서울)** | 10ms | 10ms | - |
| **인접 (서울-도쿄)** | 50ms | 10ms | **5배 빠름** |
| **중거리 (서울-싱가포르)** | 100ms | 10ms | **10배 빠름** |
| **장거리 (서울-미국)** | 150-200ms | 10ms | **15-20배 빠름** |
| **초장거리 (서울-유럽)** | 200-300ms | 10ms | **20-30배 빠름** |

---

### 가용성 비교

| 상황 | Write Replica 없음 | Write Replica 있음 |
| --- | --- | --- |
| **정상 운영** | 99.9% | 99.99% |
| **Primary 장애** | 전체 쓰기 중단 (5-10분) | 무중단 (0초) |
| **네트워크 파티션** | 격리된 지역 쓰기 불가 | 모든 지역 계속 쓰기 |
| **점진적 장애 확산** | 전체 영향 | 지역 격리 |
| **DR 복구 시간** | 5-10분 (수동 승격) | 즉시 (자동) |

---

### 부하 처리 능력

### 쓰기 처리량 (TPS - Transactions Per Second)

**Write Replica 없음:**

```
Primary DB 한계:
- 최대 10,000 TPS
- 10,000 TPS 초과 시 → 대기 시간 증가

```

**Write Replica 있음 (3개 노드):**

```
분산 처리:
- 각 노드 10,000 TPS
- 합계 30,000 TPS 처리 가능
- 3배 처리 능력 향상 🚀

```

---

## 💰 비용 비교

### 인프라 비용

**Write Replica 없음:**

```
Primary DB (대형):     $5,000/월
Read Replica x 3:      $3,000/월
총 비용:               $8,000/월

```

**Write Replica 있음:**

```
Write Node x 3 (중형): $9,000/월
복제 네트워크 비용:     $1,000/월
총 비용:              $10,000/월

```

→ **약 25% 비용 증가**, 하지만...

---

### 장애 비용 (다운타임)

**온라인 쇼핑몰 예시 (시간당 매출 1억원):**

**Write Replica 없음:**

```
연간 장애 예상:
- Primary 장애: 2회 x 10분 = 20분
- 네트워크 장애: 3회 x 5분 = 15분
- 총 다운타임: 35분/년

장애 손실:
- 35분 x (1억/60분) = 약 5,800만원/년

```

**Write Replica 있음:**

```
연간 장애 예상:
- 자동 전환으로 거의 0분
- 복잡성으로 인한 소규모 이슈: 5분

장애 손실:
- 5분 x (1억/60분) = 약 833만원/년

```

**실제 절감:**

```
손실 감소: 5,800만 - 833만 = 4,967만원/년
추가 인프라 비용: (10,000 - 8,000) x 12 = 24만원/년

순이익: 4,967만 - 24만 = 4,943만원/년 💰

```

---

## 🎯 결정 가이드

### ❌ Write Replica 필요 없음

**이런 경우:**

```
✓ 단일 지역 서비스 (한국만)
✓ 사용자 < 10만명
✓ 쓰기 부하 < 1,000 TPS
✓ 약간의 다운타임 허용 (연 99.9%)
✓ 데이터 일관성이 매우 중요 (금융 거래)
✓ 개발/운영 리소스 부족

```

**추천 아키텍처:**

```
Primary (1대) + Read Replica (2-3대) + Standby (1대)
→ 충분히 안정적이고 관리 쉬움

```

---

### ✅ Write Replica 필요함

**이런 경우:**

```
✓ 글로벌 서비스 (다중 대륙)
✓ 사용자 > 100만명
✓ 쓰기 부하 > 5,000 TPS
✓ 다운타임 허용 불가 (연 99.99%+)
✓ 낮은 레이턴시 필수 (< 50ms)
✓ 지역별 규정 준수 필요
✓ 충분한 개발/운영 리소스

```

**추천 아키텍처:**

```
Multi-Region Active-Active
→ 각 지역 Write Node + 충돌 해결 로직

```

---

## 🔧 실제 기업 사례

### Netflix (Write Replica 사용)

```
Before:
- 미국 중앙 DB
- 유럽/아시아 사용자 느림

After:
- 각 대륙별 Write Node
- 시청 기록 즉시 저장
- 추천 알고리즘 빠르게 반영

```

### Facebook (Write Replica 사용)

```
Before:
- 미국 Primary DB만 사용
- 글로벌 사용자 쓰기 지연

After:
- 각 대륙별 Write Node
- 포스트 즉시 게시
- 좋아요/댓글 즉시 반영

```

### 국내 은행 (Write Replica 미사용)

```
여전히 중앙 집중식:
- 데이터 일관성 최우선
- 규제 요구사항
- ACID 트랜잭션 필수
→ Write Replica 사용 안함

```

---

## 📊 최종 비교 요약

| 구분 | Write Replica 없음 | Write Replica 있음 |
| --- | --- | --- |
| **쓰기 레이턴시** | 지역별 차등 (10-300ms) | 모두 낮음 (10ms) |
| **가용성** | 99.9% | 99.99%+ |
| **쓰기 처리량** | 단일 노드 한계 | 노드 수만큼 증가 |
| **장애 영향** | 전체 서비스 | 지역 격리 |
| **복잡도** | 낮음 ⭐⭐ | 높음 ⭐⭐⭐⭐⭐ |
| **비용** | 낮음 💰💰 | 높음 💰💰💰💰 |
| **일관성** | 강한 일관성 | 최종 일관성 |
| **충돌 처리** | 필요 없음 | 필수 |
| **적합한 규모** | 중소형 | 대형 글로벌 |

---

## 💡 핵심 결론

### Write Replica 없음 = 단순하고 안정적

- 대부분의 서비스에 충분
- 관리 쉬움
- 강한 데이터 일관성

### Write Replica 있음 = 복잡하지만 강력

- 글로벌 서비스에 필수
- 최고의 성능과 가용성
- 복잡성과 비용 감수 필요

**결정 기준:**

```
지리적 분산 + 고가용성 + 낮은 레이턴시 요구
→ Write Replica 고려

그 외 대부분의 경우
→ Primary + Read Replica면 충분!

```



---
