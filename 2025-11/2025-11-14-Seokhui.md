# 동기, 비동기, 블로킹, 논블로킹

먼저 짚고 가야할 부분 동기≠블로킹, 비동기≠논블로킹 → 비슷하지만 다르다.

뭐가 다를까?

- 동기/비동기는 작업 완료 시점을 누가 신경쓰는가 블로킹/논블로킹은 제어권을 바로 돌려주는가

동기(Synchronous)

- 호출이 **결과를 직접 받는 순간**이 호출의 완료 시점. (호출자는 완료를 **기다린다**는 의미의 계약)
- 작업 순서가 보장됨 (A→B→C 순서대로)
- 주문한 손님(호출자)이 직접 카운터에서 "제 음식 나왔나요?"를 확인하고 받아가는 것

비동기(Asynchronous)

- 호출이 **작업만 시작**하고, 결과는 **나중에** 알림/콜백/퓨처 등으로 전달.
- 작업 순서가 보장되지 않음 (C가 A보다 먼저 끝날 수 있음)
- 진동벨을 받고 자리로 가는 것. 음식이 준비되면 식당(호출된 쪽)이 벨로 알려줌
- 은행 창구에서 일 처리하는 동안 다음 사람이 아무것도 못하고 줄 서서 기다리는 것

블로킹(Blocking)

- **호출된 함수**가 자신의 작업을 끝낼 때까지 **호출한 함수의 제어권**을 가져감
- 호출한 함수는 아무것도 못하고 대기
- 호출 스레드가 **대기 상태로 멈춘다**(CPU를 쓰지 않지만 스레드가 점유됨).
- 은행 창구에서 일 처리하는 동안 다음 사람이 아무것도 못하고 줄 서서 기다리는 것

논블로킹(Non-Blocking)

- **호출된 함수**가 바로 제어권을 **호출한 함수**에게 돌려줌
- 호출한 함수는 다른 일을 할 수 있음
- 호출 스레드가 **즉시 복귀**하여 다른 일을 계속함.
- 마트 정육점에서 "30분 뒤에 오세요"라고 하면, 그동안 다른 쇼핑을 할 수 있는 것

## 조합 가능한 4가지 케이스

## 1. 동기 + 블로킹 (가장 흔함)

```
A함수: B야, 이거 처리해줘
B함수: (제어권 가져감) 알았어, 처리할게
A함수: (제어권 없음, 대기중...)
B함수: (처리 완료) 자, 결과야
A함수: (제어권 받음) 결과 확인! 다음 작업 진행

#### CPU와 스레드 관점에서 보기

[시간축]
0초 ────────────────► 4초

[스레드 A 상태]
━━━━━━━━━━━━━━━━━━━━
작업 | 대기(블로킹) | 대기(블로킹) | 작업
━━━━━━━━━━━━━━━━━━━━
     (재고확인 2초)   (결제 2초)

[CPU 사용률]
10%  |  0%  |  0%  | 10%

스레드는 점유되어 있지만 CPU는 거의 사용하지 않음 → 비효율적!

// 1000명의 사용자가 동시 요청
// Tomcat 스레드 풀: 200개

요청 1~200: 즉시 처리 시작 (각 4초 소요)
요청 201~400: 4초 대기 후 시작 (각 4초 소요)
요청 401~600: 8초 대기 후 시작 (각 4초 소요)

→ 1000명째 사용자는 최대 12초를 기다려야 함
```

### 장점

- 코드가 **직관적**이고 읽기 쉬움 (순차적 실행)
- 디버깅이 쉬움 (스택 트레이스가 명확)
- 에러 처리가 간단함 (try-catch로 충분)
- 트랜잭션 관리가 쉬움

### 단점

- 스레드가 대기 상태로 낭비됨
- 동시 처리 가능한 요청 수가 제한적 (스레드 풀 크기만큼)
- I/O 대기 시간이 많으면 매우 비효율적
- 대용량 트래픽 처리 어려움

### 언제 사용할까?

- 트랜잭션이 중요한 CRUD 작업
- 순차적으로 처리되어야 하는 비즈니스 로직
- 트래픽이 많지 않은 서비스
- 빠른 응답이 보장되는 내부 API 호출

## 2. 동기 + 논블로킹 (드물지만 가능)

- 헷갈릴만한 포인트가 많지만 결국 동기 + 블로킹과 핵심 차이는 `병렬 처리` 여부
- 병렬처리를 하면 차이가 있지만 병렬처리를 하지 않고 작업을 하면 결국 동기/블로킹과 다를게 없다(그래서 애매함. 잘 사용X)



```
A함수: B야, 이거 처리해줘
B함수: 알았어, 시작할게 (제어권 즉시 반환)
A함수: (제어권 있음) 끝났니?
B함수: 아니
A함수: 끝났니?
B함수: 아니
A함수: 끝났니?
B함수: 응, 자 결과야
A함수: 결과 확인! 다음 작업 진행

#### CPU와 스레드 관점에서 보기

[시간축]
0초 ──────────────────► 2초

[메인 스레드 A]
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
작업 | 폴링 | 폴링 | 폴링 | ... | 결과수집
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
       ↓ 체크   ↓ 체크  ↓ 체크

[백그라운드 스레드 B1]
━━━━━━━━━━━━━━━━━━━━
  API1 호출 (2초 대기)
━━━━━━━━━━━━━━━━━━━━

[백그라운드 스레드 B2]
━━━━━━━━━━━━━━━━━━━━
  API2 호출 (1.5초 대기)
━━━━━━━━━━━━━━━━━━━━

[백그라운드 스레드 B3]
━━━━━━━━━━━━━━━━━━━━
  API3 호출 (1초 대기)
━━━━━━━━━━━━━━━━━━━━

[CPU 사용률]
메인: 10% (폴링하면서 다른 작업)
백그라운드: 0% (I/O 대기)


핵심: 메인 스레드는 논블로킹 상태를 유지하면서, 동기적으로 결과를 챙김

병렬 처리 분석

동기 + 블로킹이었다면:
API1(2초) → API2(1.5초) → API3(1초) = 총 4.5초

동기 + 논블로킹(병렬):
max(API1:2초, API2:1.5초, API3:1초) = 총 2초 + 폴링 오버헤드

→ 약 2배 빠름!
```

### 장점

- **병렬 처리** 가능 (여러 작업 동시 진행)
- **메인 스레드가 다른 작업** 가능 (UI 업데이트, 로깅 등)
- **진행 상황 모니터링** 가능
- 여러 작업의 상태를 동시에 체크 가능

### 단점

- 폴링(반복 체크)으로 인한 **CPU 낭비**
- 코드가 복잡해짐
- 적절한 폴링 주기 설정이 어려움 (너무 짧으면 CPU 낭비, 너무 길면 지연)
- 병렬 처리 안하면 의미 없음

### 언제 사용할까?

- 여러 작업을 동시에 실행하면서 진행률 표시가 필요할 때
- 파일 다운로드 중 UI 업데이트
- 배치 작업에서 각 작업의 상태를 실시간으로 모니터링
- 타임아웃 제어가 필요한 여러 API 호출

## 3. 비동기 + 논블로킹 (효율적)

```java
@RestController
public class ProductController {
    
    @GetMapping("/product/{id}")
    public Mono<ProductDetail> getProduct(@PathVariable Long id) {
        // 4개의 API를 병렬로 호출
        Mono<Product> productMono = productClient.getProduct(id);      // 1초
        Mono<Review> reviewMono = reviewClient.getReviews(id);        // 2초
        Mono<Inventory> inventoryMono = inventoryClient.getStock(id); // 1.5초
        Mono<Recommendation> recMono = recClient.getRelated(id);      // 1초
        
        // 모두 완료되면 자동으로 조합 (비동기)
        return Mono.zip(productMono, reviewMono, inventoryMono, recMono)
            .map(tuple -> new ProductDetail(
                tuple.getT1(),  // Product
                tuple.getT2(),  // Review
                tuple.getT3(),  // Inventory
                tuple.getT4()   // Recommendation
            ));
        // 메서드는 즉시 리턴 (논블로킹)
        // 결과는 나중에 자동으로 클라이언트에게 전달 (비동기)
    }
}
```

#### CPU와 스레드 관점에서 깊이 분석
```
[전체 시간축]
0초 ────────────────────► 2초

[메인 스레드 (Event Loop)]
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
요청등록 | 즉시반환 | 다른요청처리 | 다른요청처리 | ...
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  0.001초만 소요!

[I/O 스레드 풀] (별도 스레드 풀, 보통 수십 개)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
스레드1: API1 호출등록 | I/O 대기(1초) | 완료통지
스레드2: API2 호출등록 | I/O 대기(2초) | 완료통지  
스레드3: API3 호출등록 | I/O 대기(1.5초) | 완료통지
스레드4: API4 호출등록 | I/O 대기(1초) | 완료통지
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[이벤트 큐]
2초 시점: [API1완료, API2완료, API3완료, API4완료] → 콜백 실행

[CPU 사용률]
메인 스레드: 1% (거의 안씀)
I/O 스레드: 1% (대부분 네트워크 대기)
총 CPU: 2% (거의 유휴 상태)

→ 스레드는 최소한으로 사용, CPU도 거의 안씀!
```

```
A함수: B야, 이거 처리하고 끝나면 C한테 알려줘
B함수: 알았어 (제어권 즉시 반환)
A함수: (다른 작업 수행중...)
B함수: (처리 완료) C야, 처리 끝났어
C함수(콜백): 결과 받아서 처리
```

### 동작 과정 상세 설명

**1단계: 요청 등록 (0.001초)**

```java
*// 사용자 요청 도착*
GET /product/123

*// 컨트롤러 메서드 실행*
public Mono<ProductDetail> getProduct(Long id) {
    *// 각 API 호출을 "등록"만 함 (실제 호출은 나중에)*
    Mono<Product> productMono = productClient.getProduct(id);
    *// ↑ 이 순간에는 아직 API를 호출하지 않음!// 단지 "나중에 호출할 계획"을 등록만 함*
    
    return Mono.zip(...); *// 여기도 마찬가지, 계획만 등록*
}
*// 메서드 즉시 종료 (0.001초 소요)// 메인 스레드는 다음 요청을 받을 준비 완료!*
```

**2단계: 실제 실행 (구독 시점)**

```java
*// 프레임워크가 자동으로 subscribe() 호출*
mono.subscribe(); *// 이 순간 실제 실행 시작!// I/O 스레드 풀에서 실제 네트워크 호출*
스레드 A: productClient.getProduct(123) → 네트워크로 요청 전송
스레드 B: reviewClient.getReviews(123) → 네트워크로 요청 전송
스레드 C: inventoryClient.getStock(123) → 네트워크로 요청 전송
스레드 D: recClient.getRelated(123) → 네트워크로 요청 전송

*// 각 스레드는 네트워크 응답을 기다리는 동안 반납됨!// (논블로킹 I/O를 사용하기 때문)*
```

**3단계: I/O 대기 (1~2초)**
```
[운영체제 레벨]
네트워크 카드 → 패킷 전송 → 상대방 서버 처리 → 패킷 수신

이 과정에서:
- CPU는 거의 사용 안함 (1% 미만)
- 스레드도 반납되어 다른 요청 처리 가능
- 단지 네트워크 하드웨어가 일하고 있을 뿐
```

**4단계: 응답 도착 시 이벤트 발생**
```
[2초 시점]
네트워크 카드: "API2 응답 도착!"
→ 운영체제: I/O Completion 이벤트 발생
→ Event Loop: 이벤트 큐에 추가
→ 등록된 콜백 함수 실행

Mono.zip()의 콜백:
- 4개 모두 완료될 때까지 대기
- 모두 완료되면 map() 콜백 자동 실행
- ProductDetail 객체 생성
- 최종 결과를 클라이언트에게 전송
```
```

### 실제 처리 과정 시뮬레이션

**동기 블로킹 (RestTemplate)**

```java
*// 순차 실행*
Product p = restTemplate.get("/product/123");      *// 1초*
Review r = restTemplate.get("/reviews/123");       *// 2초*
Inventory i = restTemplate.get("/inventory/123");  *// 1.5초*
Recommendation re = restTemplate.get("/rec/123");  *// 1초*

총 소요 시간: 1 + 2 + 1.5 + 1 = 5.5초
사용 스레드: 1개 (계속 점유)
동시 처리 가능 요청: 200개 (스레드 풀 크기)
```

**비동기 논블로킹 (WebFlux)**

```java
*// 병렬 실행*
Mono.zip(
    client.get("/product/123"),      *// 1초*
    client.get("/reviews/123"),      *// 2초*
    client.get("/inventory/123"),    *// 1.5초*
    client.get("/rec/123")           *// 1초*
)

총 소요 시간: max(1, 2, 1.5, 1) = 2초
사용 스레드: 4개 (호출 시점에만, 곧바로 반납)
동시 처리 가능 요청: 수만 개 (이벤트 기반)
```

*// 병렬 실행*
Mono.zip(
    client.get("/product/123"),      *// 1초*
    client.get("/reviews/123"),      *// 2초*
    client.get("/inventory/123"),    *// 1.5초*
    client.get("/rec/123")           *// 1초*
)

총 소요 시간: max(1, 2, 1.5, 1) = 2초
사용 스레드: 4개 (호출 시점에만, 곧바로 반납)
동시 처리 가능 요청: 수만 개 (이벤트 기반)
```

### 백프레셔(Backpressure) 지원

**백프레셔란?**
```
생산자(Producer): 데이터를 만드는 쪽
소비자(Consumer): 데이터를 처리하는 쪽

문제: 생산자가 소비자보다 빠르면?
→ 데이터가 쌓이고 쌓여서 메모리 부족!

백프레셔: 소비자가 처리 가능한 만큼만 요청
→ 메모리 안전성 확보
```

**백프레셔 전략**

```java
*// 1. BUFFER: 버퍼에 저장 (메모리 위험)*
flux.onBackpressureBuffer(1000);

*// 2. DROP: 넘치는 데이터 버림*
flux.onBackpressureDrop();

*// 3. LATEST: 최신 데이터만 유지*
flux.onBackpressureLatest();

*// 4. ERROR: 에러 발생*
flux.onBackpressureError();
```



### 장점

- **극도로 높은 처리량** (TPS)
- **최소한의 스레드로 최대 효율**
- **메모리 사용량 최소화**
- **병렬 처리 자동화** (코드에서 명시적 처리 불필요)
- **백프레셔(Backpressure) 지원** (과부하 제어)

### 단점

- **학습 곡선이 가파름** (Reactive Programming)
- **디버깅이 매우 어려움** (스택 트레이스가 복잡)
- **에러 처리가 복잡함**
- **블로킹 코드와 섞으면 성능 저하** (JDBC 등)
- **팀원 전체가 학습해야 함**
- **트랜잭션 관리가 어려움**

### 언제 사용할까?

- **대용량 트래픽 처리** (MSA의 API Gateway)
- **외부 API 호출이 많은 경우**
- **실시간 스트리밍** (채팅, 알림, 주가)
    - 데이터를 조각내서 흘려보낸다
    - 일반 방식 (Batch)
    
    ```java
    [데이터 전체를 모았다가 한 번에]
    
    서버: 100만 개 데이터 준비 중... (30초)
    서버: 준비 완료! 전송! (5초)
    클라이언트: 받음! 처리 시작
    
    → 35초 후에야 첫 데이터를 볼 수 있음
    ```
    
    - 스트리밍 방식
    
    ```java
    [만들어지는 즉시 흘려보냄]
    
    서버: 1개 준비 → 즉시 전송 (0.1초)
    서버: 1개 준비 → 즉시 전송 (0.2초)
    서버: 1개 준비 → 즉시 전송 (0.3초)
    ...계속...
    
    → 0.1초 후부터 데이터를 볼 수 있음
    ```
    

## 4. 비동기 + 블로킹 (비효율적, 거의 안씀)

- 결국에 비동기로 동작은 하지만 블로킹 되어 결국에 대기하게 됨. (비동기의 이점을 지움)
- 의도했다기 보다는 비동기로 선언해놓고 블로킹 처리 해버리는 실수에서 많이 나옴
- 그렇기 때문에 안티패턴이며 따로 장점도 없다.

```
A함수: B야, 이거 처리하고 끝나면 알려줘
B함수: (제어권 가져감) 처리중...
A함수: (제어권 없음, 대기중... 뭔가 이상함)
B함수: (처리 완료, 제어권 반환) 끝났어
A함수: 어? 비동기인데 왜 기다렸지?
```

## 예외나 롤백은 어떻게 처리됨?

### 동기 + 논블로킹(병렬 처리)

- 다른 스레드 = 다른 커넥션 = 독립적 트랜잭션
- 성공한 작업은 커밋, 실패한 작업만 롤백
- 각 작업의 성공/실패를 Result 객체로 추적 가능

**실행 결과:**
```
[0.0초] 작업 1~10 동시 시작 (10개 스레드)

작업 1 시작 (스레드: pool-1-thread-1)
작업 2 시작 (스레드: pool-1-thread-2)
작업 3 시작 (스레드: pool-1-thread-3)
작업 4 시작 (스레드: pool-1-thread-4)
작업 5 시작 (스레드: pool-1-thread-5) ← 예외 발생 예정
작업 6 시작 (스레드: pool-1-thread-6)
작업 7 시작 (스레드: pool-1-thread-7)
작업 8 시작 (스레드: pool-1-thread-8) ← 예외 발생 예정
작업 9 시작 (스레드: pool-1-thread-9)
작업 10 시작 (스레드: pool-1-thread-10)

[1초 후]
작업 1 성공 (DB에 커밋됨)
작업 2 성공 (DB에 커밋됨)
작업 3 성공 (DB에 커밋됨)
작업 4 성공 (DB에 커밋됨)
작업 5 실패: RuntimeException (롤백됨, DB에 저장 안됨)
작업 6 성공 (DB에 커밋됨)
작업 7 성공 (DB에 커밋됨)
작업 8 실패: RuntimeException (롤백됨, DB에 저장 안됨)
작업 9 성공 (DB에 커밋됨)
작업 10 성공 (DB에 커밋됨)

최종 결과:
- 성공: 8개 (1,2,3,4,6,7,9,10) → DB에 저장됨
- 실패: 2개 (5,8) → DB에 저장 안됨
- results 리스트에 각 작업의 성공/실패 정보 포함
```

### 비동기 + 논블로킹

- 메인 스레드(Event Loop): 요청만 받고 즉시 응답
- 백그라운드 스레드: 실제 작업 수행
- 각 요청은 완전히 독립적 (서로 영향 없음)
- 사용자 통지 방법
    - 웹훅/푸시 알림
    - 상태 조회 API (폴링)
    - Server-Sent Events (실시간 스트리미)

### 100개 요청, 10개 스레드 시나리오

### 전체 실행 과정

```
[시작 시점: 0.000초]

100개 요청이 들어옴

Netty Event Loop (메인 스레드): 8개
I/O 스레드 풀 (백그라운드): 10개

┌─────────────────────────────────────────┐
│  Netty Event Loop (메인 스레드)         │
│  - 요청 받기                             │
│  - 즉시 Mono 반환                        │
│  - 다른 요청 계속 받음                   │
└─────────────────────────────────────────┘
            ↓ (비동기로 위임)
┌─────────────────────────────────────────┐
│  I/O 스레드 풀 (백그라운드 스레드)      │
│  - 실제 작업 수행                        │
│  - 10개씩 처리                           │
└─────────────────────────────────────────┘

```

### 상세 타임라인

```
[0.000초] 100개 요청 도착

Netty Event Loop 스레드들 (8개)
├─ reactor-http-nio-1
│  ├─ 요청 1 받음 → Mono 생성 → 즉시 응답 "요청 접수"
│  ├─ 요청 9 받음 → Mono 생성 → 즉시 응답 "요청 접수"
│  ├─ 요청 17 받음 → Mono 생성 → 즉시 응답 "요청 접수"
│  └─ ... (계속 요청 받음)
│
├─ reactor-http-nio-2
│  ├─ 요청 2 받음 → Mono 생성 → 즉시 응답 "요청 접수"
│  └─ ... (계속 요청 받음)
│
└─ ... (나머지 6개 Event Loop도 동일)

→ 100개 요청 모두 0.1초 안에 "요청 접수" 응답 보냄!
→ 클라이언트들은 모두 "성공" 화면 봄 ✅

[0.001초] 백그라운드 작업 시작

I/O 스레드 풀 (10개 스레드)
├─ parallel-1  → 요청 1의 작업들 실행
├─ parallel-2  → 요청 2의 작업들 실행
├─ parallel-3  → 요청 3의 작업들 실행
├─ parallel-4  → 요청 4의 작업들 실행
├─ parallel-5  → 요청 5의 작업들 실행
├─ parallel-6  → 요청 6의 작업들 실행
├─ parallel-7  → 요청 7의 작업들 실행 ← 여기서 장애 예정
├─ parallel-8  → 요청 8의 작업들 실행
├─ parallel-9  → 요청 9의 작업들 실행
└─ parallel-10 → 요청 10의 작업들 실행

나머지 90개는 큐에서 대기 중...

```

### 요청 7번의 상세 실행

```
[parallel-7 스레드의 실행 과정]

0.001초: task1 시작
         - orderRepository.save() 호출
         - DB 커넥션 A 획득
         - 트랜잭션 A 시작

0.010초: task1 완료
         - 트랜잭션 A 커밋
         - DB에 저장됨 ✅
         - 커넥션 A 반납

0.011초: task2 시작
         - productRepository.save() 호출
         - DB 커넥션 B 획득
         - 트랜잭션 B 시작

0.020초: task2 완료
         - 트랜잭션 B 커밋
         - DB에 저장됨 ✅
         - 커넥션 B 반납

0.021초: task3 시작
         - paymentClient.call() 호출
         - DB 커넥션 C 획득
         - 트랜잭션 C 시작

0.030초: task3 실패! ❌
         - 예외 발생: PaymentFailedException
         - 트랜잭션 C 롤백
         - 커넥션 C 반납

0.031초: 에러 처리
         - onError 콜백 실행
         - task4, task5는 실행 안됨

결과:
- task1, task2 → DB에 저장됨 (이미 커밋됨)
- task3 → 롤백됨
- task4, task5 → 실행 안됨
```