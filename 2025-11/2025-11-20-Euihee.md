# Kafka의 Offset, ACK, CDC 정리

---

## 1. Offset

Kafka의 Offset은 **Consumer Group이 특정 Topic Partition에서 어디까지 읽었는지 나타내는 논리적 위치 정보**이다.

### Offset 저장 위치

- Offset은 Kafka 내부 토픽인 `__consumer_offsets`에 저장된다.
- 이 토픽은 **Compacted Log 기반**이며, 최신 상태만 유지하면서 저장 공간을 최소화한다.
- Offset의 **논리적 소유자는 Consumer Group**이지만, **물리적 저장·관리 주체는 Kafka Broker**이다.

### Offset 재처리 방법

- 메시지를 처음부터 다시 읽고 싶다면:
    - Consumer Group ID를 변경 또는 신규 Consumer Group 생성하여 처리한다.
    - 또는 프로그래밍적으로 `seek(offset)` 사용 가능
---
## 2. ACK

Kafka Producer는 메시지 전송 성공 여부를 `acks` 설정값으로 제어한다.

### ISR(In-Sync Replicas)

- 리더와 거의 동일한 offset을 유지하고 있는 Replica의 집합
- 네트워크/디스크 지연으로 뒤처진 Replica는 ISR에서 제외된다.

### acks 옵션별 의미

| 설정 | 확인 범위                   | 신뢰성 | 성능 |
|------|-------------------------|--------|------|
| `acks=0` | Leader 조차 확인하지 않고 보내고 끝 | 최악 | 최고 |
| `acks=1` | Leader에만 기록되면 확인        | 중간 | 중간 |
| `acks=all` 또는 `acks=-1` | Leader + 모든 ISR 확인      | 최고 | 낮음 |

- `acks=all`은 Replica 전체가 아니고 ISR에 속한 Replica만 확인한다.
- 다만, ISR에 속한 Replica 수가 많아질수록 성능이 저하될 수 있다.
- 반드시 `min.insync.replicas` 값과 함께 설정해야 한다.

예시:

```properties
acks=all
min.insync.replicas=2
```

→ ISR이 2개 이상 유지되지 않으면 Producer는 메시지 쓰기를 실패 처리한다.

---

## 3. CDC (Change Data Capture)

CDC는 **DB의 데이터 변경 사항 CUD를 실시간으로 감지하여 Kafka Topic에 전송하는 기술**이다.

### 방식

- 단순 폴링이나 DB Trigger 방식이 아니라,
- **DB의 트랜잭션 로그(WAL/binlog/redo log)를 읽는 구조**
- 따라서 운영 DB 부하를 최소화하고 지연 시간(Latency)을 극도로 줄일 수 있다.

### 실제 구현에서 많이 쓰는 조합

- **Kafka Connect + Debezium**
- Debezium은 DB 로그를 해석해 변경 이벤트를 Kafka 메시지 형태로 변환한다.
- 2025 우아콘에서도 Kafka Connect + Debezium 를 활용한 사례가 세션 3개나 있었다.
- CDC를 활용하면 **마이크로서비스 간 데이터 동기화, 실시간 분석, 이벤트 소싱, DB 변경시 데이터 동기화** 등 다양한 아키텍처 패턴을 구현할 수 있다.